Sender: LSF System <lsfadmin@lo-s4-031>
Subject: Job 3737592: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 10:02:44 2020
Job was executed on host(s) <3*lo-s4-031>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 10:03:12 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 10:03:12 2020
Terminated at Sun Jan  5 10:05:40 2020
Results reported at Sun Jan  5 10:05:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   159.46 sec.
    Max Memory :                                 5790 MB
    Average Memory :                             4184.57 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               117090.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   172 sec.
    Turnaround time :                            176 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 196, in <module>
    for batch_idx, batch in enumerate(train_loader):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-031>
Subject: Job 3737594: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 10:05:52 2020
Job was executed on host(s) <3*lo-s4-031>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 10:06:11 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 10:06:11 2020
Terminated at Sun Jan  5 10:10:12 2020
Results reported at Sun Jan  5 10:10:12 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   274.39 sec.
    Max Memory :                                 6562 MB
    Average Memory :                             4364.90 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               116318.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   263 sec.
    Turnaround time :                            260 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 204, in <module>
    true_im = add_noise(batch["img",0]) #Before cropping original image  noise needs to be added 
  File "train_gan.py", line 171, in add_noise
    noise = Variable(ins.data.new(ins.size()).normal_(mean, stddev))
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-026>
Subject: Job 3737595: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 10:10:02 2020
Job was executed on host(s) <3*lo-s4-026>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 10:10:12 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 10:10:12 2020
Terminated at Sun Jan  5 10:13:00 2020
Results reported at Sun Jan  5 10:13:00 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   184.28 sec.
    Max Memory :                                 6112 MB
    Average Memory :                             4481.00 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               116768.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   189 sec.
    Turnaround time :                            178 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
Traceback (most recent call last):
  File "train_gan.py", line 196, in <module>
    for batch_idx, batch in enumerate(train_loader):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-029>
Subject: Job 3737844: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 12:08:59 2020
Job was executed on host(s) <3*lo-s4-029>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 12:09:04 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 12:09:04 2020
Terminated at Sun Jan  5 12:09:10 2020
Results reported at Sun Jan  5 12:09:10 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1.75 sec.
    Max Memory :                                 282 MB
    Average Memory :                             281.00 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               122598.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                5
    Run time :                                   24 sec.
    Turnaround time :                            11 sec.

The output (if any) follows:

Traceback (most recent call last):
  File "train_gan.py", line 19, in <module>
    from gan_model import CS_Dataset
  File "/cluster/home/takmaza/ExPGAN/gan_model.py", line 41
    print('type: ' type(loaded_img))
                      ^
SyntaxError: invalid syntax
Sender: LSF System <lsfadmin@lo-s4-034>
Subject: Job 3737860: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 12:14:38 2020
Job was executed on host(s) <3*lo-s4-034>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 12:15:05 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 12:15:05 2020
Terminated at Sun Jan  5 12:15:43 2020
Results reported at Sun Jan  5 12:15:43 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   25.15 sec.
    Max Memory :                                 3904 MB
    Average Memory :                             2555.00 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               118976.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   67 sec.
    Turnaround time :                            65 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
Traceback (most recent call last):
  File "train_gan.py", line 196, in <module>
    for batch_idx, batch in enumerate(train_loader):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-029>
Subject: Job 3737898: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 12:41:15 2020
Job was executed on host(s) <3*lo-s4-029>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 12:41:36 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 12:41:36 2020
Terminated at Sun Jan  5 12:45:30 2020
Results reported at Sun Jan  5 12:45:30 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   288.76 sec.
    Max Memory :                                 7577 MB
    Average Memory :                             5212.50 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               115303.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   246 sec.
    Turnaround time :                            255 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 196, in <module>
    writers[mode] = SummaryWriter(os.path.join(opt.log_path, mode))
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-029>
Subject: Job 3737906: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 12:46:01 2020
Job was executed on host(s) <3*lo-s4-029>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 12:46:05 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 12:46:05 2020
Terminated at Sun Jan  5 12:46:10 2020
Results reported at Sun Jan  5 12:46:10 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   0.24 sec.
    Max Memory :                                 11 MB
    Average Memory :                             6.00 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               122869.00 MB
    Max Swap :                                   -
    Max Processes :                              1
    Max Threads :                                1
    Run time :                                   9 sec.
    Turnaround time :                            9 sec.

The output (if any) follows:

  File "train_gan.py", line 188
    weight_segmentation = mask_tensor.repeat(opt.batch_size 256, 1)
                                                              ^
SyntaxError: invalid syntax
Sender: LSF System <lsfadmin@lo-s4-010>
Subject: Job 3737908: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 12:47:35 2020
Job was executed on host(s) <3*lo-s4-010>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 12:47:35 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 12:47:35 2020
Terminated at Sun Jan  5 12:47:37 2020
Results reported at Sun Jan  5 12:47:37 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   0.31 sec.
    Max Memory :                                 6 MB
    Average Memory :                             -
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               122874.00 MB
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   9 sec.
    Turnaround time :                            2 sec.

The output (if any) follows:

  File "train_gan.py", line 289
    loss_seg = weight_segmentation*loss_seg # Ensure that weights are scaled appropriately
                                                                                         ^
TabError: inconsistent use of tabs and spaces in indentation
Sender: LSF System <lsfadmin@lo-s4-029>
Subject: Job 3737911: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 12:48:22 2020
Job was executed on host(s) <3*lo-s4-029>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 12:48:35 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 12:48:35 2020
Terminated at Sun Jan  5 12:48:51 2020
Results reported at Sun Jan  5 12:48:51 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   13.29 sec.
    Max Memory :                                 2760 MB
    Average Memory :                             232.00 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               120120.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                7
    Run time :                                   39 sec.
    Turnaround time :                            29 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 289, in <module>
    loss_seg = weight_segmentation*loss_seg # Ensure that weights are scaled appropriately
RuntimeError: expected device cpu but got device cuda:0
Sender: LSF System <lsfadmin@lo-s4-029>
Subject: Job 3737915: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 12:52:16 2020
Job was executed on host(s) <3*lo-s4-029>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 12:52:35 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 12:52:35 2020
Terminated at Sun Jan  5 12:53:31 2020
Results reported at Sun Jan  5 12:53:31 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   59.14 sec.
    Max Memory :                                 3542 MB
    Average Memory :                             2462.75 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               119338.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   68 sec.
    Turnaround time :                            75 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 210, in <module>
    for batch_idx, batch in enumerate(train_loader):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-029>
Subject: Job 3737918: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 12:54:24 2020
Job was executed on host(s) <3*lo-s4-029>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 12:54:35 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 12:54:35 2020
Terminated at Sun Jan  5 13:20:44 2020
Results reported at Sun Jan  5 13:20:44 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1872.69 sec.
    Max Memory :                                 14114 MB
    Average Memory :                             11280.17 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               108766.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   1571 sec.
    Turnaround time :                            1580 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
Switched to eval mode
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Epoch 0: validation_loss=743.2653017044067, best_validation_loss=None 
Saving models to /cluster/scratch/takmaza/DL/project_extrapolation/model3 
##############################
Epoch: 1
Traceback (most recent call last):
  File "train_gan.py", line 269, in <module>
    gen_fake_left, gen_fake_right, gen_fake_seg = generator_G(source_img, source_segm)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/takmaza/ExPGAN/gan_model.py", line 259, in forward
    seg_u7= self.seg_up7(seg_u6)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/takmaza/ExPGAN/gan_model.py", line 138, in forward
    out = self.block(x)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/container.py", line 92, in forward
    input = module(input)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/upsampling.py", line 131, in forward
    return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py", line 2518, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, _output_size(2), align_corners)
RuntimeError: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 7.93 GiB total capacity; 7.27 GiB already allocated; 24.56 MiB free; 111.96 MiB cached)
Sender: LSF System <lsfadmin@lo-s4-050>
Subject: Job 3738520: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 16:01:57 2020
Job was executed on host(s) <6*lo-s4-050>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 16:02:11 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 16:02:11 2020
Terminated at Sun Jan  5 16:24:22 2020
Results reported at Sun Jan  5 16:24:22 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1688.26 sec.
    Max Memory :                                 16874 MB
    Average Memory :                             13230.87 MB
    Total Requested Memory :                     245760.00 MB
    Delta Memory :                               228886.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   1359 sec.
    Turnaround time :                            1345 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
Switched to eval mode
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Epoch 0: validation_loss=642.4205484390259, best_validation_loss=None 
Saving models to /cluster/scratch/takmaza/DL/project_extrapolation/model3 
##############################
Epoch: 1
Traceback (most recent call last):
  File "train_gan.py", line 269, in <module>
    gen_fake_left, gen_fake_right, gen_fake_seg = generator_G(source_img, source_segm)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/takmaza/ExPGAN/gan_model.py", line 259, in forward
    seg_u7= self.seg_up7(seg_u6)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/takmaza/ExPGAN/gan_model.py", line 138, in forward
    out = self.block(x)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/container.py", line 92, in forward
    input = module(input)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/upsampling.py", line 131, in forward
    return F.interpolate(input, self.size, self.scale_factor, self.mode, self.align_corners)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py", line 2518, in interpolate
    return torch._C._nn.upsample_bilinear2d(input, _output_size(2), align_corners)
RuntimeError: CUDA out of memory. Tried to allocate 126.00 MiB (GPU 0; 7.93 GiB total capacity; 7.27 GiB already allocated; 24.56 MiB free; 111.96 MiB cached)
Sender: LSF System <lsfadmin@lo-s4-078>
Subject: Job 3738597: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 16:32:56 2020
Job was executed on host(s) <8*lo-s4-078>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 16:33:10 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 16:33:10 2020
Terminated at Sun Jan  5 16:35:41 2020
Results reported at Sun Jan  5 16:35:41 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   173.20 sec.
    Max Memory :                                 7712 MB
    Average Memory :                             5426.14 MB
    Total Requested Memory :                     327680.00 MB
    Delta Memory :                               319968.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   180 sec.
    Turnaround time :                            165 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 312, in <module>
    optimizer_G.step()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/optim/adam.py", line 96, in step
    exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-082>
Subject: Job 3738596: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 16:32:48 2020
Job was executed on host(s) <8*lo-s4-082>, in queue <gpu.24h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 16:33:10 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 16:33:10 2020
Terminated at Sun Jan  5 19:05:17 2020
Results reported at Sun Jan  5 19:05:17 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   10211.65 sec.
    Max Memory :                                 19216 MB
    Average Memory :                             17177.67 MB
    Total Requested Memory :                     327680.00 MB
    Delta Memory :                               308464.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   9153 sec.
    Turnaround time :                            9149 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
Switched to eval mode
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Epoch 0: validation_loss=506.28860807418823, best_validation_loss=None 
Saving models to /cluster/scratch/takmaza/DL/project_extrapolation/model3 
##############################
Epoch: 1
Switched to eval mode
Epoch 1: validation_loss=717.5949354171753, best_validation_loss=506.28860807418823 
##############################
Epoch: 2
Switched to eval mode
Epoch 2: validation_loss=651.7265124320984, best_validation_loss=506.28860807418823 
##############################
Epoch: 3
Switched to eval mode
Epoch 3: validation_loss=184.49629640579224, best_validation_loss=506.28860807418823 
Saving models to /cluster/scratch/takmaza/DL/project_extrapolation/model3 
##############################
Epoch: 4
Switched to eval mode
Epoch 4: validation_loss=772.1610021591187, best_validation_loss=184.49629640579224 
##############################
Epoch: 5
Switched to eval mode
Epoch 5: validation_loss=578.9107060432434, best_validation_loss=184.49629640579224 
##############################
Epoch: 6
Switched to eval mode
Epoch 6: validation_loss=169.15116572380066, best_validation_loss=184.49629640579224 
Saving models to /cluster/scratch/takmaza/DL/project_extrapolation/model3 
##############################
Epoch: 7
Traceback (most recent call last):
  File "train_gan.py", line 208, in <module>
    for batch_idx, batch in enumerate(train_loader):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-078>
Subject: Job 3738951: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 19:06:03 2020
Job was executed on host(s) <8*lo-s4-078>, in queue <gpu.24h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 19:06:17 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 19:06:17 2020
Terminated at Mon Jan  6 19:06:16 2020
Results reported at Mon Jan  6 19:06:16 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_RUNLIMIT: job killed after reaching LSF run time limit.
Exited with exit code 140.

Resource usage summary:

    CPU time :                                   98698.00 sec.
    Max Memory :                                 18733 MB
    Average Memory :                             17086.54 MB
    Total Requested Memory :                     327680.00 MB
    Delta Memory :                               308947.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   86427 sec.
    Turnaround time :                            86413 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
Switched to eval mode
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Epoch 0: validation_loss=327.5425980091095, best_validation_loss=None 
Saving models to /cluster/scratch/takmaza/DL/project_extrapolation/model3 
##############################
Epoch: 1
Switched to eval mode
Epoch 1: validation_loss=239.70567059516907, best_validation_loss=327.5425980091095 
Saving models to /cluster/scratch/takmaza/DL/project_extrapolation/model3 
##############################
Epoch: 2
Switched to eval mode
Epoch 2: validation_loss=1001.5961999893188, best_validation_loss=239.70567059516907 
##############################
Epoch: 3
Switched to eval mode
Epoch 3: validation_loss=205.00421285629272, best_validation_loss=239.70567059516907 
Saving models to /cluster/scratch/takmaza/DL/project_extrapolation/model3 
##############################
Epoch: 4
Switched to eval mode
Epoch 4: validation_loss=561.5706734657288, best_validation_loss=205.00421285629272 
##############################
Epoch: 5
Switched to eval mode
Epoch 5: validation_loss=729.2250738143921, best_validation_loss=205.00421285629272 
##############################
Epoch: 6
Switched to eval mode
Epoch 6: validation_loss=1038.4099283218384, best_validation_loss=205.00421285629272 
##############################
Epoch: 7
Switched to eval mode
Epoch 7: validation_loss=697.3391380310059, best_validation_loss=205.00421285629272 
##############################
Epoch: 8
Switched to eval mode
Epoch 8: validation_loss=783.5072937011719, best_validation_loss=205.00421285629272 
##############################
Epoch: 9
Switched to eval mode
Epoch 9: validation_loss=742.1166086196899, best_validation_loss=205.00421285629272 
##############################
Epoch: 10
Switched to eval mode
Epoch 10: validation_loss=615.8422541618347, best_validation_loss=205.00421285629272 
##############################
Epoch: 11
Switched to eval mode
Epoch 11: validation_loss=913.5115032196045, best_validation_loss=205.00421285629272 
##############################
Epoch: 12
Switched to eval mode
Epoch 12: validation_loss=556.6955323219299, best_validation_loss=205.00421285629272 
##############################
Epoch: 13
Switched to eval mode
Epoch 13: validation_loss=764.062647819519, best_validation_loss=205.00421285629272 
##############################
Epoch: 14
Switched to eval mode
Epoch 14: validation_loss=738.0216131210327, best_validation_loss=205.00421285629272 
##############################
Epoch: 15
Switched to eval mode
Epoch 15: validation_loss=926.5273132324219, best_validation_loss=205.00421285629272 
##############################
Epoch: 16
Switched to eval mode
Epoch 16: validation_loss=988.5461702346802, best_validation_loss=205.00421285629272 
##############################
Epoch: 17
Switched to eval mode
Epoch 17: validation_loss=742.5282068252563, best_validation_loss=205.00421285629272 
##############################
Epoch: 18
Switched to eval mode
Epoch 18: validation_loss=558.2799458503723, best_validation_loss=205.00421285629272 
##############################
Epoch: 19
Switched to eval mode
Epoch 19: validation_loss=915.3554811477661, best_validation_loss=205.00421285629272 
##############################
Epoch: 20
Switched to eval mode
Epoch 20: validation_loss=807.53542137146, best_validation_loss=205.00421285629272 
##############################
Epoch: 21
Switched to eval mode
Epoch 21: validation_loss=782.5052576065063, best_validation_loss=205.00421285629272 
##############################
Epoch: 22
Switched to eval mode
Epoch 22: validation_loss=980.8098440170288, best_validation_loss=205.00421285629272 
##############################
Epoch: 23
Switched to eval mode
Epoch 23: validation_loss=654.4963178634644, best_validation_loss=205.00421285629272 
##############################
Epoch: 24
Switched to eval mode
Epoch 24: validation_loss=966.9371213912964, best_validation_loss=205.00421285629272 
##############################
Epoch: 25
Switched to eval mode
Epoch 25: validation_loss=946.4648866653442, best_validation_loss=205.00421285629272 
##############################
Epoch: 26
Switched to eval mode
Epoch 26: validation_loss=1060.4162073135376, best_validation_loss=205.00421285629272 
##############################
Epoch: 27
Switched to eval mode
Epoch 27: validation_loss=891.8983144760132, best_validation_loss=205.00421285629272 
##############################
Epoch: 28
Switched to eval mode
Epoch 28: validation_loss=1053.2626638412476, best_validation_loss=205.00421285629272 
##############################
Epoch: 29
Switched to eval mode
Epoch 29: validation_loss=1051.6538457870483, best_validation_loss=205.00421285629272 
##############################
Epoch: 30
Switched to eval mode
Epoch 30: validation_loss=1338.4141788482666, best_validation_loss=205.00421285629272 
##############################
Epoch: 31
Switched to eval mode
Epoch 31: validation_loss=1599.6167297363281, best_validation_loss=205.00421285629272 
##############################
Epoch: 32
Switched to eval mode
Epoch 32: validation_loss=956.5794734954834, best_validation_loss=205.00421285629272 
##############################
Epoch: 33
Switched to eval mode
Epoch 33: validation_loss=1287.8156805038452, best_validation_loss=205.00421285629272 
##############################
Epoch: 34
Switched to eval mode
Epoch 34: validation_loss=1106.4323348999023, best_validation_loss=205.00421285629272 
##############################
Epoch: 35
Switched to eval mode
Epoch 35: validation_loss=1054.6135349273682, best_validation_loss=205.00421285629272 
##############################
Epoch: 36
Switched to eval mode
Epoch 36: validation_loss=1217.6177387237549, best_validation_loss=205.00421285629272 
##############################
Epoch: 37
Switched to eval mode
Epoch 37: validation_loss=1064.9458265304565, best_validation_loss=205.00421285629272 
##############################
Epoch: 38
Switched to eval mode
Epoch 38: validation_loss=1306.581316947937, best_validation_loss=205.00421285629272 
##############################
Epoch: 39
Switched to eval mode
Epoch 39: validation_loss=1485.0722398757935, best_validation_loss=205.00421285629272 
##############################
Epoch: 40
Switched to eval mode
Epoch 40: validation_loss=970.1612415313721, best_validation_loss=205.00421285629272 
##############################
Epoch: 41
Switched to eval mode
Epoch 41: validation_loss=1123.138216972351, best_validation_loss=205.00421285629272 
##############################
Epoch: 42
Switched to eval mode
Epoch 42: validation_loss=1252.8211822509766, best_validation_loss=205.00421285629272 
##############################
Epoch: 43
Switched to eval mode
Epoch 43: validation_loss=1074.0105829238892, best_validation_loss=205.00421285629272 
##############################
Epoch: 44
Switched to eval mode
Epoch 44: validation_loss=1408.2086334228516, best_validation_loss=205.00421285629272 
##############################
Epoch: 45
Switched to eval mode
Epoch 45: validation_loss=1174.4353408813477, best_validation_loss=205.00421285629272 
##############################
Epoch: 46
Switched to eval mode
Epoch 46: validation_loss=911.0683250427246, best_validation_loss=205.00421285629272 
##############################
Epoch: 47
Switched to eval mode
Epoch 47: validation_loss=1316.3828897476196, best_validation_loss=205.00421285629272 
##############################
Epoch: 48
Switched to eval mode
Epoch 48: validation_loss=1180.5871887207031, best_validation_loss=205.00421285629272 
##############################
Epoch: 49
Switched to eval mode
Epoch 49: validation_loss=1009.4932231903076, best_validation_loss=205.00421285629272 
##############################
Epoch: 50
Switched to eval mode
Epoch 50: validation_loss=1563.668737411499, best_validation_loss=205.00421285629272 
##############################
Epoch: 51
Switched to eval mode
Epoch 51: validation_loss=1496.1391296386719, best_validation_loss=205.00421285629272 
##############################
Epoch: 52
Switched to eval mode
Epoch 52: validation_loss=1016.0228786468506, best_validation_loss=205.00421285629272 
##############################
Epoch: 53
Switched to eval mode
Epoch 53: validation_loss=1139.8587398529053, best_validation_loss=205.00421285629272 
##############################
Epoch: 54
Switched to eval mode
Epoch 54: validation_loss=1610.8296737670898, best_validation_loss=205.00421285629272 
##############################
Epoch: 55
Switched to eval mode
Epoch 55: validation_loss=1372.4276142120361, best_validation_loss=205.00421285629272 
##############################
Epoch: 56
Switched to eval mode
Epoch 56: validation_loss=1011.8125219345093, best_validation_loss=205.00421285629272 
##############################
Epoch: 57
Switched to eval mode
Epoch 57: validation_loss=2012.8636379241943, best_validation_loss=205.00421285629272 
##############################
Epoch: 58
Switched to eval mode
Epoch 58: validation_loss=1071.6469640731812, best_validation_loss=205.00421285629272 
##############################
Epoch: 59
Switched to eval mode
Epoch 59: validation_loss=1128.7727737426758, best_validation_loss=205.00421285629272 
##############################
Epoch: 60
Switched to eval mode
Epoch 60: validation_loss=927.6676511764526, best_validation_loss=205.00421285629272 
##############################
Epoch: 61
Switched to eval mode
Epoch 61: validation_loss=1320.9910221099854, best_validation_loss=205.00421285629272 
##############################
Epoch: 62
Switched to eval mode
Epoch 62: validation_loss=1490.5531463623047, best_validation_loss=205.00421285629272 
##############################
Epoch: 63
Switched to eval mode
Epoch 63: validation_loss=1255.591389656067, best_validation_loss=205.00421285629272 
##############################
Epoch: 64
Switched to eval mode
Epoch 64: validation_loss=857.8234901428223, best_validation_loss=205.00421285629272 
##############################
Epoch: 65
Switched to eval mode
Epoch 65: validation_loss=777.3157558441162, best_validation_loss=205.00421285629272 
##############################
Epoch: 66
Switched to eval mode
Epoch 66: validation_loss=1182.054063796997, best_validation_loss=205.00421285629272 
##############################
Epoch: 67
Switched to eval mode
Epoch 67: validation_loss=1481.085340499878, best_validation_loss=205.00421285629272 
##############################
Epoch: 68
Switched to eval mode
Epoch 68: validation_loss=1221.4408569335938, best_validation_loss=205.00421285629272 
##############################
Epoch: 69
Switched to eval mode
Epoch 69: validation_loss=1209.7615098953247, best_validation_loss=205.00421285629272 
##############################
Epoch: 70
Switched to eval mode
Epoch 70: validation_loss=1239.6859226226807, best_validation_loss=205.00421285629272 
##############################
Epoch: 71
User defined signal 2
Sender: LSF System <lsfadmin@lo-s4-083>
Subject: Job 3750871: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-02> by user <takmaza> in cluster <leonhard> at Tue Jan  7 07:19:40 2020
Job was executed on host(s) <8*lo-s4-083>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Tue Jan  7 08:40:06 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Tue Jan  7 08:40:06 2020
Terminated at Tue Jan  7 11:24:48 2020
Results reported at Tue Jan  7 11:24:48 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   11955.07 sec.
    Max Memory :                                 20530 MB
    Average Memory :                             18750.46 MB
    Total Requested Memory :                     327680.00 MB
    Delta Memory :                               307150.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   9888 sec.
    Turnaround time :                            14708 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
Switched to eval mode
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Epoch 0: validation_loss=919.4077978134155, best_validation_loss=None 
Saving models to /cluster/scratch/takmaza/DL/project_extrapolation/model3 
##############################
Epoch: 1
Switched to eval mode
Epoch 1: validation_loss=1457.0295124053955, best_validation_loss=919.4077978134155 
##############################
Epoch: 2
Switched to eval mode
Epoch 2: validation_loss=1447.8519878387451, best_validation_loss=919.4077978134155 
##############################
Epoch: 3
Switched to eval mode
Epoch 3: validation_loss=991.1243925094604, best_validation_loss=919.4077978134155 
##############################
Epoch: 4
Switched to eval mode
Epoch 4: validation_loss=1197.7658281326294, best_validation_loss=919.4077978134155 
##############################
Epoch: 5
Switched to eval mode
Epoch 5: validation_loss=954.2735185623169, best_validation_loss=919.4077978134155 
##############################
Epoch: 6
Switched to eval mode
Epoch 6: validation_loss=298.1357493400574, best_validation_loss=919.4077978134155 
Saving models to /cluster/scratch/takmaza/DL/project_extrapolation/model3 
##############################
Epoch: 7
Switched to eval mode
Epoch 7: validation_loss=743.2997198104858, best_validation_loss=298.1357493400574 
##############################
Epoch: 8
Switched to eval mode
Epoch 8: validation_loss=1033.6061086654663, best_validation_loss=298.1357493400574 
##############################
Epoch: 9
Traceback (most recent call last):
  File "train_gan.py", line 210, in <module>
    
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-078>
Subject: Job 3753076: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Tue Jan  7 11:25:08 2020
Job was executed on host(s) <8*lo-s4-078>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Tue Jan  7 11:25:35 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Tue Jan  7 11:25:35 2020
Terminated at Tue Jan  7 11:25:36 2020
Results reported at Tue Jan  7 11:25:36 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   0.30 sec.
    Max Memory :                                 11 MB
    Average Memory :                             -
    Total Requested Memory :                     327680.00 MB
    Delta Memory :                               327669.00 MB
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   30 sec.
    Turnaround time :                            28 sec.

The output (if any) follows:

  File "train_gan.py", line 125
    return(res)
    ^
SyntaxError: 'return' outside function
Sender: LSF System <lsfadmin@lo-s4-078>
Subject: Job 3753079: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Tue Jan  7 11:26:27 2020
Job was executed on host(s) <8*lo-s4-078>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Tue Jan  7 11:26:34 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Tue Jan  7 11:26:34 2020
Terminated at Tue Jan  7 11:26:37 2020
Results reported at Tue Jan  7 11:26:37 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   0.29 sec.
    Max Memory :                                 6 MB
    Average Memory :                             -
    Total Requested Memory :                     327680.00 MB
    Delta Memory :                               327674.00 MB
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   30 sec.
    Turnaround time :                            10 sec.

The output (if any) follows:

  File "train_gan.py", line 125
    return(res)
              ^
TabError: inconsistent use of tabs and spaces in indentation
Sender: LSF System <lsfadmin@lo-s4-078>
Subject: Job 3753081: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Tue Jan  7 11:27:11 2020
Job was executed on host(s) <8*lo-s4-078>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Tue Jan  7 11:27:34 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Tue Jan  7 11:27:34 2020
Terminated at Tue Jan  7 11:34:21 2020
Results reported at Tue Jan  7 11:34:21 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   501.42 sec.
    Max Memory :                                 14513 MB
    Average Memory :                             9348.06 MB
    Total Requested Memory :                     327680.00 MB
    Delta Memory :                               313167.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   430 sec.
    Turnaround time :                            430 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 320, in <module>
    loss_seg = torch.mean(loss_seg) # Sums the loss per image
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/loss.py", line 498, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py", line 2065, in binary_cross_entropy
    input, target, weight, reduction_enum)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-009>
Subject: Job 3753282: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Tue Jan  7 12:23:47 2020
Job was executed on host(s) <4*lo-s4-009>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Tue Jan  7 12:24:05 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Tue Jan  7 12:24:05 2020
Terminated at Tue Jan  7 12:25:02 2020
Results reported at Tue Jan  7 12:25:02 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   68.45 sec.
    Max Memory :                                 4494 MB
    Average Memory :                             3116.25 MB
    Total Requested Memory :                     163840.00 MB
    Delta Memory :                               159346.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   81 sec.
    Turnaround time :                            75 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 239, in <module>
    for batch_idx, batch in enumerate(train_loader):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-020>
Subject: Job 3753316: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Tue Jan  7 12:28:11 2020
Job was executed on host(s) <4*lo-s4-020>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Tue Jan  7 12:28:36 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Tue Jan  7 12:28:36 2020
Terminated at Tue Jan  7 12:28:40 2020
Results reported at Tue Jan  7 12:28:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1.69 sec.
    Max Memory :                                 290 MB
    Average Memory :                             -
    Total Requested Memory :                     163840.00 MB
    Delta Memory :                               163550.00 MB
    Max Swap :                                   -
    Max Processes :                              -
    Max Threads :                                -
    Run time :                                   32 sec.
    Turnaround time :                            29 sec.

The output (if any) follows:

Traceback (most recent call last):
  File "train_gan.py", line 162, in <module>
    logging(str(opt))
  File "train_gan.py", line 69, in logging
    with open(os.path.join(model_save_dir, log_file), 'a') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/cluster/scratch/takmaza/DL/models/2020171228/logs.txt'
Sender: LSF System <lsfadmin@lo-s4-009>
Subject: Job 3753370: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Tue Jan  7 12:33:56 2020
Job was executed on host(s) <4*lo-s4-009>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Tue Jan  7 12:34:07 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Tue Jan  7 12:34:07 2020
Terminated at Tue Jan  7 12:46:05 2020
Results reported at Tue Jan  7 12:46:05 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   976.89 sec.
    Max Memory :                                 15927 MB
    Average Memory :                             10251.87 MB
    Total Requested Memory :                     163840.00 MB
    Delta Memory :                               147913.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   743 sec.
    Turnaround time :                            729 sec.

The output (if any) follows:

Namespace(b1=0.5, b2=0.999, batch_size=8, clip_value=0.01, dataset_folder='/cluster/scratch/takmaza/DL', img_size=28, lambda_disc=1.0, lambda_recon=1.0, lambda_seg=1.0, log_frequency=20, logfile_name='logs.txt', lr=0.0002, model_save='/cluster/scratch/takmaza/DL/', n_cpu=8, n_critic=5, num_epochs=200, sample_interval=400)
cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 240, in <module>
    #Switch models to training mode
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-038>
Subject: Job 3753503: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Tue Jan  7 12:46:08 2020
Job was executed on host(s) <4*lo-s4-038>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Tue Jan  7 12:46:37 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Tue Jan  7 12:46:37 2020
Terminated at Tue Jan  7 12:52:29 2020
Results reported at Tue Jan  7 12:52:29 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   450.99 sec.
    Max Memory :                                 9951 MB
    Average Memory :                             6459.86 MB
    Total Requested Memory :                     163840.00 MB
    Delta Memory :                               153889.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   376 sec.
    Turnaround time :                            381 sec.

The output (if any) follows:

Namespace(b1_disc=0.5, b1_gen=0.5, b2_disc=0.999, b2_gen=0.999, batch_size=8, clip_value=0.01, dataset_folder='/cluster/scratch/takmaza/DL', img_size=28, lambda_disc=1.0, lambda_recon=1.0, lambda_seg=1.0, log_frequency=20, logfile_name='logs.txt', lr_disc=0.002, lr_gen=0.0002, mini_D_num_epochs=1, mini_G_num_epochs=1, model_save='/cluster/scratch/takmaza/DL/', n_cpu=8, n_critic=5, num_epochs=200, sample_interval=400)
cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x2af2ef8752f0>
Traceback (most recent call last):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 925, in __del__
    def __del__(self):
KeyboardInterrupt
Traceback (most recent call last):
  File "train_gan.py", line 359, in <module>
    optimizer_G.step()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/optim/adam.py", line 96, in step
    exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-009>
Subject: Job 3753556: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Tue Jan  7 12:52:42 2020
Job was executed on host(s) <4*lo-s4-009>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Tue Jan  7 12:53:06 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Tue Jan  7 12:53:06 2020
Terminated at Tue Jan  7 12:54:45 2020
Results reported at Tue Jan  7 12:54:45 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   127.87 sec.
    Max Memory :                                 5273 MB
    Average Memory :                             3606.60 MB
    Total Requested Memory :                     163840.00 MB
    Delta Memory :                               158567.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   125 sec.
    Turnaround time :                            123 sec.

The output (if any) follows:

Namespace(b1_disc=0.5, b1_gen=0.5, b2_disc=0.999, b2_gen=0.999, batch_size=8, clip_value=0.01, dataset_folder='/cluster/scratch/takmaza/DL', img_size=28, lambda_disc=1.0, lambda_recon=1.0, lambda_seg=1.0, log_frequency=20, logfile_name='logs.txt', lr_disc=0.002, lr_gen=0.0002, mini_D_num_epochs=1, mini_G_num_epochs=1, model_save='/cluster/scratch/takmaza/DL/', n_cpu=8, n_critic=5, num_epochs=200, sample_interval=400)
cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 359, in <module>
    optimizer_G.step()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/optim/adam.py", line 95, in step
    exp_avg.mul_(beta1).add_(1 - beta1, grad)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-020>
Subject: Job 3753576: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Tue Jan  7 12:54:51 2020
Job was executed on host(s) <4*lo-s4-020>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Tue Jan  7 12:55:06 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Tue Jan  7 12:55:06 2020
Terminated at Tue Jan  7 12:56:09 2020
Results reported at Tue Jan  7 12:56:09 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   80.53 sec.
    Max Memory :                                 4755 MB
    Average Memory :                             3193.75 MB
    Total Requested Memory :                     163840.00 MB
    Delta Memory :                               159085.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   71 sec.
    Turnaround time :                            78 sec.

The output (if any) follows:

Namespace(b1_disc=0.5, b1_gen=0.5, b2_disc=0.999, b2_gen=0.999, batch_size=8, clip_value=0.01, dataset_folder='/cluster/scratch/takmaza/DL', img_size=28, lambda_disc=1.0, lambda_recon=1.0, lambda_seg=1.0, log_frequency=20, logfile_name='logs.txt', lr_disc=0.002, lr_gen=0.0002, mini_D_num_epochs=1, mini_G_num_epochs=1, model_save='/cluster/scratch/takmaza/DL/', n_cpu=8, n_critic=5, num_epochs=200, sample_interval=400)
cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 339, in <module>
    loss_D_left = adversarial_loss(torch.squeeze(lbl_est_left), torch.squeeze(true_lbl))
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/loss.py", line 498, in forward
    return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py", line 2065, in binary_cross_entropy
    input, target, weight, reduction_enum)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-046>
Subject: Job 3753591: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Tue Jan  7 12:56:20 2020
Job was executed on host(s) <4*lo-s4-046>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Tue Jan  7 12:56:36 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Tue Jan  7 12:56:36 2020
Terminated at Tue Jan  7 12:57:05 2020
Results reported at Tue Jan  7 12:57:05 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   30.62 sec.
    Max Memory :                                 3928 MB
    Average Memory :                             2504.67 MB
    Total Requested Memory :                     163840.00 MB
    Delta Memory :                               159912.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   56 sec.
    Turnaround time :                            45 sec.

The output (if any) follows:

Namespace(b1_disc=0.5, b1_gen=0.5, b2_disc=0.999, b2_gen=0.999, batch_size=8, clip_value=0.01, dataset_folder='/cluster/scratch/takmaza/DL', img_size=28, lambda_disc=1.0, lambda_recon=1.0, lambda_seg=1.0, log_frequency=20, logfile_name='logs.txt', lr_disc=0.002, lr_gen=0.0002, mini_D_num_epochs=1, mini_G_num_epochs=1, model_save='/cluster/scratch/takmaza/DL/', n_cpu=8, n_critic=5, num_epochs=200, sample_interval=400)
cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 244, in <module>
    for batch_idx, batch in enumerate(train_loader):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-078>
Subject: Job 3767246: <python train_gan_load.py --model_load=/cluster/scratch/takmaza/DL/models/2020-01-08-0731-model.pt> in cluster <leonhard> Exited

Job <python train_gan_load.py --model_load=/cluster/scratch/takmaza/DL/models/2020-01-08-0731-model.pt> was submitted from host <lo-login-02> by user <takmaza> in cluster <leonhard> at Fri Jan 10 01:40:48 2020
Job was executed on host(s) <6*lo-s4-078>, in queue <gpu.24h>, as user <takmaza> in cluster <leonhard> at Fri Jan 10 01:40:56 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Fri Jan 10 01:40:56 2020
Terminated at Fri Jan 10 01:41:00 2020
Results reported at Fri Jan 10 01:41:00 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan_load.py --model_load=/cluster/scratch/takmaza/DL/models/2020-01-08-0731-model.pt
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1.61 sec.
    Max Memory :                                 284 MB
    Average Memory :                             279.00 MB
    Total Requested Memory :                     245760.00 MB
    Delta Memory :                               245476.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                5
    Run time :                                   16 sec.
    Turnaround time :                            12 sec.

The output (if any) follows:

Traceback (most recent call last):
  File "train_gan_load.py", line 61, in <module>
    model_save_dir = get_model_name(opt)
  File "train_gan_load.py", line 58, in get_model_name
    os.makedirs(writer_log_dir)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib64/python3.7/os.py", line 221, in makedirs
    mkdir(name, mode)
FileExistsError: [Errno 17] File exists: '/cluster/scratch/takmaza/DL/models/2020-01-10-0141'
Sender: LSF System <lsfadmin@lo-s4-077>
Subject: Job 3767245: <python train_gan_load.py --model_load=/cluster/scratch/takmaza/DL/models/2020-01-08-0731-model.pt> in cluster <leonhard> Exited

Job <python train_gan_load.py --model_load=/cluster/scratch/takmaza/DL/models/2020-01-08-0731-model.pt> was submitted from host <lo-login-02> by user <takmaza> in cluster <leonhard> at Fri Jan 10 01:40:38 2020
Job was executed on host(s) <6*lo-s4-077>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Fri Jan 10 01:40:56 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Fri Jan 10 01:40:56 2020
Terminated at Fri Jan 10 01:41:01 2020
Results reported at Fri Jan 10 01:41:01 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan_load.py --model_load=/cluster/scratch/takmaza/DL/models/2020-01-08-0731-model.pt
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1.76 sec.
    Max Memory :                                 283 MB
    Average Memory :                             276.00 MB
    Total Requested Memory :                     245760.00 MB
    Delta Memory :                               245477.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                5
    Run time :                                   19 sec.
    Turnaround time :                            23 sec.

The output (if any) follows:

Namespace(b1_disc=0.5, b1_gen=0.5, b2_disc=0.999, b2_gen=0.999, batch_size=8, clip_value=0.01, dataset_folder='/cluster/scratch/takmaza/DL', img_size=28, lambda_disc=1.0, lambda_recon=1.0, lambda_seg=1.0, log_frequency=20, logfile_name='logs.txt', lr_disc=0.002, lr_gen=0.0002, mini_D_num_epochs=1, mini_G_num_epochs=1, model_load='/cluster/scratch/takmaza/DL/models/2020-01-08-0731-model.pt', model_save='/cluster/scratch/takmaza/DL/', n_cpu=8, n_critic=5, num_epochs=200, sample_interval=400)
cuda status:  True
Traceback (most recent call last):
  File "train_gan_load.py", line 188, in <module>
    if model_load == "":
NameError: name 'model_load' is not defined
Sender: LSF System <lsfadmin@lo-s4-077>
Subject: Job 3767250: <python train_gan_load.py --model_load=/cluster/scratch/takmaza/DL/models/2020-01-08-0731-model.pt> in cluster <leonhard> Exited

Job <python train_gan_load.py --model_load=/cluster/scratch/takmaza/DL/models/2020-01-08-0731-model.pt> was submitted from host <lo-login-02> by user <takmaza> in cluster <leonhard> at Fri Jan 10 01:42:31 2020
Job was executed on host(s) <6*lo-s4-077>, in queue <gpu.24h>, as user <takmaza> in cluster <leonhard> at Fri Jan 10 01:42:55 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Fri Jan 10 01:42:55 2020
Terminated at Fri Jan 10 01:49:12 2020
Results reported at Fri Jan 10 01:49:12 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan_load.py --model_load=/cluster/scratch/takmaza/DL/models/2020-01-08-0731-model.pt
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   404.17 sec.
    Max Memory :                                 12105 MB
    Average Memory :                             8028.87 MB
    Total Requested Memory :                     245760.00 MB
    Delta Memory :                               233655.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   399 sec.
    Turnaround time :                            401 sec.

The output (if any) follows:

Namespace(b1_disc=0.5, b1_gen=0.5, b2_disc=0.999, b2_gen=0.999, batch_size=8, clip_value=0.01, dataset_folder='/cluster/scratch/takmaza/DL', img_size=28, lambda_disc=1.0, lambda_recon=1.0, lambda_seg=1.0, log_frequency=20, logfile_name='logs.txt', lr_disc=0.002, lr_gen=0.0002, mini_D_num_epochs=1, mini_G_num_epochs=1, model_load='/cluster/scratch/takmaza/DL/models/2020-01-08-0731-model.pt', model_save='/cluster/scratch/takmaza/DL/', n_cpu=8, n_critic=5, num_epochs=200, sample_interval=400)
cuda status:  True
Loading models from /cluster/scratch/takmaza/DL/models/2020-01-08-0731-model.pt 
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan_load.py", line 249, in <module>
    for batch_idx, batch in enumerate(train_loader):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-077>
Subject: Job 3767319: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-02> by user <takmaza> in cluster <leonhard> at Fri Jan 10 02:05:43 2020
Job was executed on host(s) <6*lo-s4-077>, in queue <gpu.24h>, as user <takmaza> in cluster <leonhard> at Fri Jan 10 02:05:55 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Fri Jan 10 02:05:55 2020
Terminated at Fri Jan 10 02:12:20 2020
Results reported at Fri Jan 10 02:12:20 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   435.40 sec.
    Max Memory :                                 12086 MB
    Average Memory :                             7631.47 MB
    Total Requested Memory :                     245760.00 MB
    Delta Memory :                               233674.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   396 sec.
    Turnaround time :                            397 sec.

The output (if any) follows:

Namespace(b1_disc=0.5, b1_gen=0.5, b2_disc=0.999, b2_gen=0.999, batch_size=8, clip_value=0.01, dataset_folder='/cluster/scratch/takmaza/DL', img_size=28, lambda_disc=1.0, lambda_recon=1.0, lambda_seg=1.0, log_frequency=20, logfile_name='logs.txt', lr_disc=0.002, lr_gen=0.0002, mini_D_num_epochs=1, mini_G_num_epochs=1, model_load='', model_save='/cluster/scratch/takmaza/DL/', n_cpu=8, n_critic=5, num_epochs=200, sample_interval=400)
cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 249, in <module>
    for batch_idx, batch in enumerate(train_loader):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-078>
Subject: Job 3767344: <python train_gan.py --lr_gen=0.001 --mini_D_num_epochs=3> in cluster <leonhard> Exited

Job <python train_gan.py --lr_gen=0.001 --mini_D_num_epochs=3> was submitted from host <lo-login-02> by user <takmaza> in cluster <leonhard> at Fri Jan 10 02:16:08 2020
Job was executed on host(s) <6*lo-s4-078>, in queue <gpu.24h>, as user <takmaza> in cluster <leonhard> at Fri Jan 10 02:16:26 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Fri Jan 10 02:16:26 2020
Terminated at Fri Jan 10 02:16:59 2020
Results reported at Fri Jan 10 02:16:59 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py --lr_gen=0.001 --mini_D_num_epochs=3
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   38.19 sec.
    Max Memory :                                 4763 MB
    Average Memory :                             3145.67 MB
    Total Requested Memory :                     245760.00 MB
    Delta Memory :                               240997.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   56 sec.
    Turnaround time :                            51 sec.

The output (if any) follows:

Namespace(b1_disc=0.5, b1_gen=0.5, b2_disc=0.999, b2_gen=0.999, batch_size=8, clip_value=0.01, dataset_folder='/cluster/scratch/takmaza/DL', img_size=28, lambda_disc=1.0, lambda_recon=1.0, lambda_seg=1.0, log_frequency=20, logfile_name='logs.txt', lr_disc=0.002, lr_gen=0.001, mini_D_num_epochs=3, mini_G_num_epochs=1, model_load='', model_save='/cluster/scratch/takmaza/DL/', n_cpu=8, n_critic=5, num_epochs=200, sample_interval=400)
cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 249, in <module>
    for batch_idx, batch in enumerate(train_loader):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-083>
Subject: Job 3767340: <python train_gan.py --lr_gen=0.001 --mini_D_num_epochs=3> in cluster <leonhard> Exited

Job <python train_gan.py --lr_gen=0.001 --mini_D_num_epochs=3> was submitted from host <lo-login-02> by user <takmaza> in cluster <leonhard> at Fri Jan 10 02:14:37 2020
Job was executed on host(s) <6*lo-s4-083>, in queue <gpu.24h>, as user <takmaza> in cluster <leonhard> at Fri Jan 10 02:14:56 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Fri Jan 10 02:14:56 2020
Terminated at Fri Jan 10 07:47:10 2020
Results reported at Fri Jan 10 07:47:10 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py --lr_gen=0.001 --mini_D_num_epochs=3
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   25992.70 sec.
    Max Memory :                                 18921 MB
    Average Memory :                             17701.26 MB
    Total Requested Memory :                     245760.00 MB
    Delta Memory :                               226839.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   19959 sec.
    Turnaround time :                            19953 sec.

The output (if any) follows:

Namespace(b1_disc=0.5, b1_gen=0.5, b2_disc=0.999, b2_gen=0.999, batch_size=8, clip_value=0.01, dataset_folder='/cluster/scratch/takmaza/DL', img_size=28, lambda_disc=1.0, lambda_recon=1.0, lambda_seg=1.0, log_frequency=20, logfile_name='logs.txt', lr_disc=0.002, lr_gen=0.001, mini_D_num_epochs=3, mini_G_num_epochs=1, model_load='', model_save='/cluster/scratch/takmaza/DL/', n_cpu=8, n_critic=5, num_epochs=200, sample_interval=400)
cuda status:  True
Switched to training mode
##############################
Epoch: 0
Switched to eval mode
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Epoch 0: validation_loss=-1598.7915744781494, best_validation_loss=None 
Saving models to /cluster/scratch/takmaza/DL/models/2020-01-10-0215 
##############################
Epoch: 1
Switched to eval mode
Epoch 1: validation_loss=-1600.0719032287598, best_validation_loss=-1598.7915744781494 
##############################
Epoch: 2
Switched to eval mode
Epoch 2: validation_loss=-1599.5281562805176, best_validation_loss=-1600.0719032287598 
##############################
Epoch: 3
Switched to eval mode
Epoch 3: validation_loss=-1600.0548133850098, best_validation_loss=-1600.0719032287598 
##############################
Epoch: 4
Switched to eval mode
Epoch 4: validation_loss=-1600.7802352905273, best_validation_loss=-1600.0719032287598 
##############################
Epoch: 5
Switched to eval mode
Epoch 5: validation_loss=-1601.5376720428467, best_validation_loss=-1600.7802352905273 
Saving models to /cluster/scratch/takmaza/DL/models/2020-01-10-0215 
##############################
Epoch: 6
Switched to eval mode
Epoch 6: validation_loss=-1601.6541862487793, best_validation_loss=-1601.5376720428467 
##############################
Epoch: 7
Switched to eval mode
Epoch 7: validation_loss=-1601.3391227722168, best_validation_loss=-1601.6541862487793 
##############################
Epoch: 8
Switched to eval mode
Epoch 8: validation_loss=-1601.2322063446045, best_validation_loss=-1601.6541862487793 
##############################
Epoch: 9
Switched to eval mode
Epoch 9: validation_loss=-1601.6072254180908, best_validation_loss=-1601.6541862487793 
##############################
Epoch: 10
Switched to eval mode
Epoch 10: validation_loss=-1601.4816036224365, best_validation_loss=-1601.6541862487793 
Saving models to /cluster/scratch/takmaza/DL/models/2020-01-10-0215 
##############################
Epoch: 11
Switched to eval mode
Epoch 11: validation_loss=-1601.8187255859375, best_validation_loss=-1601.6541862487793 
##############################
Epoch: 12
Switched to eval mode
Epoch 12: validation_loss=-1601.6138305664062, best_validation_loss=-1601.8187255859375 
##############################
Epoch: 13
Switched to eval mode
Epoch 13: validation_loss=-1601.3858814239502, best_validation_loss=-1601.8187255859375 
##############################
Epoch: 14
Switched to eval mode
Epoch 14: validation_loss=-1601.0858612060547, best_validation_loss=-1601.8187255859375 
##############################
Epoch: 15
Switched to eval mode
Epoch 15: validation_loss=-1601.0548419952393, best_validation_loss=-1601.8187255859375 
Saving models to /cluster/scratch/takmaza/DL/models/2020-01-10-0215 
##############################
Epoch: 16
Traceback (most recent call last):
  File "train_gan.py", line 323, in <module>
    lbl_est_right = right_D(fake_right)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/takmaza/ExPGAN/gan_model.py", line 336, in forward
    validity = self.model(img)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/container.py", line 92, in forward
    input = module(input)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 345, in forward
    return self.conv2d_forward(input, self.weight)
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 342, in conv2d_forward
    self.padding, self.dilation, self.groups)
KeyboardInterrupt
