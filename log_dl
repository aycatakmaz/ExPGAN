Sender: LSF System <lsfadmin@lo-s4-031>
Subject: Job 3737592: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 10:02:44 2020
Job was executed on host(s) <3*lo-s4-031>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 10:03:12 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 10:03:12 2020
Terminated at Sun Jan  5 10:05:40 2020
Results reported at Sun Jan  5 10:05:40 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   159.46 sec.
    Max Memory :                                 5790 MB
    Average Memory :                             4184.57 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               117090.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   172 sec.
    Turnaround time :                            176 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 196, in <module>
    for batch_idx, batch in enumerate(train_loader):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-031>
Subject: Job 3737594: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 10:05:52 2020
Job was executed on host(s) <3*lo-s4-031>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 10:06:11 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 10:06:11 2020
Terminated at Sun Jan  5 10:10:12 2020
Results reported at Sun Jan  5 10:10:12 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   274.39 sec.
    Max Memory :                                 6562 MB
    Average Memory :                             4364.90 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               116318.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   263 sec.
    Turnaround time :                            260 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
Traceback (most recent call last):
  File "train_gan.py", line 204, in <module>
    true_im = add_noise(batch["img",0]) #Before cropping original image  noise needs to be added 
  File "train_gan.py", line 171, in add_noise
    noise = Variable(ins.data.new(ins.size()).normal_(mean, stddev))
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-026>
Subject: Job 3737595: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 10:10:02 2020
Job was executed on host(s) <3*lo-s4-026>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 10:10:12 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 10:10:12 2020
Terminated at Sun Jan  5 10:13:00 2020
Results reported at Sun Jan  5 10:13:00 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   184.28 sec.
    Max Memory :                                 6112 MB
    Average Memory :                             4481.00 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               116768.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   189 sec.
    Turnaround time :                            178 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
SHAPE:
gen_fake_seg torch.Size([8, 33, 256, 512])
masked_target_before_max torch.Size([8, 33, 256, 512])
masked_target_after_max torch.Size([8, 256, 512])
Traceback (most recent call last):
  File "train_gan.py", line 196, in <module>
    for batch_idx, batch in enumerate(train_loader):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
Sender: LSF System <lsfadmin@lo-s4-029>
Subject: Job 3737844: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 12:08:59 2020
Job was executed on host(s) <3*lo-s4-029>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 12:09:04 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 12:09:04 2020
Terminated at Sun Jan  5 12:09:10 2020
Results reported at Sun Jan  5 12:09:10 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   1.75 sec.
    Max Memory :                                 282 MB
    Average Memory :                             281.00 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               122598.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                5
    Run time :                                   24 sec.
    Turnaround time :                            11 sec.

The output (if any) follows:

Traceback (most recent call last):
  File "train_gan.py", line 19, in <module>
    from gan_model import CS_Dataset
  File "/cluster/home/takmaza/ExPGAN/gan_model.py", line 41
    print('type: ' type(loaded_img))
                      ^
SyntaxError: invalid syntax
Sender: LSF System <lsfadmin@lo-s4-034>
Subject: Job 3737860: <python train_gan.py> in cluster <leonhard> Exited

Job <python train_gan.py> was submitted from host <lo-login-01> by user <takmaza> in cluster <leonhard> at Sun Jan  5 12:14:38 2020
Job was executed on host(s) <3*lo-s4-034>, in queue <gpu.4h>, as user <takmaza> in cluster <leonhard> at Sun Jan  5 12:15:05 2020
</cluster/home/takmaza> was used as the home directory.
</cluster/home/takmaza/ExPGAN> was used as the working directory.
Started at Sun Jan  5 12:15:05 2020
Terminated at Sun Jan  5 12:15:43 2020
Results reported at Sun Jan  5 12:15:43 2020

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python train_gan.py
------------------------------------------------------------

TERM_OWNER: job killed by owner.
Exited with exit code 1.

Resource usage summary:

    CPU time :                                   25.15 sec.
    Max Memory :                                 3904 MB
    Average Memory :                             2555.00 MB
    Total Requested Memory :                     122880.00 MB
    Delta Memory :                               118976.00 MB
    Max Swap :                                   -
    Max Processes :                              4
    Max Threads :                                18
    Run time :                                   67 sec.
    Turnaround time :                            65 sec.

The output (if any) follows:

cuda status:  True
Switched to training mode
##############################
Epoch: 0
/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/nn/functional.py:2494: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  "See the documentation of nn.Upsample for details.".format(mode))
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
type:  <class 'PIL.Image.Image'>
Max val:  255
Traceback (most recent call last):
  File "train_gan.py", line 196, in <module>
    for batch_idx, batch in enumerate(train_loader):
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 804, in __next__
    idx, data = self._get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 761, in _get_data
    success, data = self._try_get_data()
  File "/cluster/home/takmaza/.virtualenvs/dsc-env/lib/python3.7/site-packages/torch/utils/data/dataloader.py", line 724, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/queue.py", line 179, in get
    self.not_empty.wait(remaining)
  File "/cluster/apps/python/3.7.1/x86_64/lib64/python3.7/threading.py", line 300, in wait
    gotit = waiter.acquire(True, timeout)
KeyboardInterrupt
